{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15637aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install librosa soundfile pandas scikit-learn tensorflow==2.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a237f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, random, itertools, functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52774a2",
   "metadata": {},
   "source": [
    "Constructing Pathing and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ccd89c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer(classes=[&#x27;Accelerating_and_revving_and_vroom&#x27;, &#x27;Accordion&#x27;,\n",
       "                             &#x27;Acoustic_guitar&#x27;, &#x27;Aircraft&#x27;, &#x27;Alarm&#x27;, &#x27;Animal&#x27;,\n",
       "                             &#x27;Applause&#x27;, &#x27;Bark&#x27;, &#x27;Bass_drum&#x27;, &#x27;Bass_guitar&#x27;,\n",
       "                             &#x27;Bathtub_(filling_or_washing)&#x27;, &#x27;Bell&#x27;, &#x27;Bicycle&#x27;,\n",
       "                             &#x27;Bicycle_bell&#x27;, &#x27;Bird&#x27;,\n",
       "                             &#x27;Bird_vocalization_and_bird_call_and_bird_song&#x27;,\n",
       "                             &#x27;Boat_and_Water_vehicle&#x27;, &#x27;Boiling&#x27;, &#x27;Boom&#x27;,\n",
       "                             &#x27;Bowed_string_instrument&#x27;, &#x27;Brass_instrument&#x27;,\n",
       "                             &#x27;Breathing&#x27;, &#x27;Burping_and_eructation&#x27;, &#x27;Bus&#x27;,\n",
       "                             &#x27;Buzz&#x27;, &#x27;Camera&#x27;, &#x27;Car&#x27;, &#x27;Car_passing_by&#x27;, &#x27;Cat&#x27;,\n",
       "                             &#x27;Chatter&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultiLabelBinarizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\">?<span>Documentation for MultiLabelBinarizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultiLabelBinarizer(classes=[&#x27;Accelerating_and_revving_and_vroom&#x27;, &#x27;Accordion&#x27;,\n",
       "                             &#x27;Acoustic_guitar&#x27;, &#x27;Aircraft&#x27;, &#x27;Alarm&#x27;, &#x27;Animal&#x27;,\n",
       "                             &#x27;Applause&#x27;, &#x27;Bark&#x27;, &#x27;Bass_drum&#x27;, &#x27;Bass_guitar&#x27;,\n",
       "                             &#x27;Bathtub_(filling_or_washing)&#x27;, &#x27;Bell&#x27;, &#x27;Bicycle&#x27;,\n",
       "                             &#x27;Bicycle_bell&#x27;, &#x27;Bird&#x27;,\n",
       "                             &#x27;Bird_vocalization_and_bird_call_and_bird_song&#x27;,\n",
       "                             &#x27;Boat_and_Water_vehicle&#x27;, &#x27;Boiling&#x27;, &#x27;Boom&#x27;,\n",
       "                             &#x27;Bowed_string_instrument&#x27;, &#x27;Brass_instrument&#x27;,\n",
       "                             &#x27;Breathing&#x27;, &#x27;Burping_and_eructation&#x27;, &#x27;Bus&#x27;,\n",
       "                             &#x27;Buzz&#x27;, &#x27;Camera&#x27;, &#x27;Car&#x27;, &#x27;Car_passing_by&#x27;, &#x27;Cat&#x27;,\n",
       "                             &#x27;Chatter&#x27;, ...])</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer(classes=['Accelerating_and_revving_and_vroom', 'Accordion',\n",
       "                             'Acoustic_guitar', 'Aircraft', 'Alarm', 'Animal',\n",
       "                             'Applause', 'Bark', 'Bass_drum', 'Bass_guitar',\n",
       "                             'Bathtub_(filling_or_washing)', 'Bell', 'Bicycle',\n",
       "                             'Bicycle_bell', 'Bird',\n",
       "                             'Bird_vocalization_and_bird_call_and_bird_song',\n",
       "                             'Boat_and_Water_vehicle', 'Boiling', 'Boom',\n",
       "                             'Bowed_string_instrument', 'Brass_instrument',\n",
       "                             'Breathing', 'Burping_and_eructation', 'Bus',\n",
       "                             'Buzz', 'Camera', 'Car', 'Car_passing_by', 'Cat',\n",
       "                             'Chatter', ...])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming database is in a folder \"FSD50K\" in the same directory as this .ipynb\n",
    "ROOT = \"FSD50K\"\n",
    "\n",
    "DEV_AUDIO = os.path.join(ROOT, \"FSD50K.dev_audio\")\n",
    "EVAL_AUDIO = os.path.join(ROOT, \"FSD50K.eval_audio\")\n",
    "GT_DIR    = os.path.join(ROOT, \"FSD50K.ground_truth\")\n",
    "# print(GT_DIR)\n",
    "dev_df  = pd.read_csv(GT_DIR + \"/\" + \"dev.csv\")\n",
    "eval_df = pd.read_csv(GT_DIR + \"/\" + \"eval.csv\") # testing data\n",
    "vocab   = pd.read_csv(GT_DIR + \"/\" + \"vocabulary.csv\", header=None)\n",
    "# print(vocab)\n",
    "\n",
    "# Labels in dev/eval are comma-separated strings\n",
    "def split_labels(s): \n",
    "    return [t for t in str(s).split(\",\") if t]\n",
    "\n",
    "all_labels = sorted(vocab.iloc[:, 1].tolist()) # Extract all possible labels\n",
    "mlb = MultiLabelBinarizer(classes=all_labels)    # fixed class ordering\n",
    "mlb.fit([all_labels])  # initialize with full set so order is stable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbcfeeb",
   "metadata": {},
   "source": [
    "Getting the Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e3d79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dev_df[dev_df[\"split\"]==\"train\"].copy() # extract training data\n",
    "val_df   = dev_df[dev_df[\"split\"]==\"val\"].copy() # extract validation data\n",
    "\n",
    "# Helper function to convert metadata rows into file paths and label arrays\n",
    "# df is either the training, validation, or testing data frame\n",
    "# audio_base is the directory path that has the audio files\n",
    "def rows_to_examples(df, audio_base):\n",
    "    fnames = df[\"fname\"].astype(str).tolist()\n",
    "    paths  = [os.path.join(audio_base, f\"{f}.wav\") for f in fnames]\n",
    "    labels = [split_labels(s) for s in df[\"labels\"].tolist()]\n",
    "    Y      = mlb.transform(labels).astype(\"float32\")\n",
    "    return paths, Y\n",
    "\n",
    "train_paths, y_train = rows_to_examples(train_df, DEV_AUDIO)\n",
    "val_paths,   y_val   = rows_to_examples(val_df,   DEV_AUDIO)\n",
    "eval_paths,  y_eval  = rows_to_examples(eval_df,  EVAL_AUDIO)\n",
    "NUM_CLASSES = len(all_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f70a8e",
   "metadata": {},
   "source": [
    "Preprocessing audio to make all samples 32 kHz and 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9527cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "SR          = 22050\n",
    "DURATION    = 15.0\n",
    "N_MELS      = 64\n",
    "HOP_LENGTH  = 512\n",
    "N_FFT       = 1024\n",
    "\n",
    "import math, numpy as np, librosa, tensorflow as tf\n",
    "\n",
    "# Exact frame count used in training\n",
    "T = math.ceil((SR * DURATION) / HOP_LENGTH) + 1\n",
    "\n",
    "def load_mel(path):\n",
    "    # unwrap what tf.numpy_function hands us\n",
    "    if isinstance(path, np.ndarray):     # 0-D object array\n",
    "        path = path.item()\n",
    "    if isinstance(path, (bytes, np.bytes_)):\n",
    "        path = path.decode(\"utf-8\")\n",
    "    path = str(path)\n",
    "\n",
    "    # Use librosa.load for robust decoding on Windows\n",
    "    y, _ = librosa.load(path, sr=SR, mono=True)\n",
    "\n",
    "    # pad/crop waveform to fixed duration\n",
    "    target_len = int(SR * DURATION)\n",
    "    if len(y) < target_len:\n",
    "        y = np.pad(y, (0, target_len - len(y)))\n",
    "    else:\n",
    "        y = y[:target_len]\n",
    "\n",
    "    # log-mel\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS, power=2.0\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max).astype(np.float32)  # [mels, frames]\n",
    "    return np.expand_dims(S_db, -1)  # [mels, frames, 1]\n",
    "\n",
    "def tf_load_mel(path, label):\n",
    "    path = tf.cast(path, tf.string)\n",
    "\n",
    "    mel = tf.numpy_function(load_mel, [path], tf.float32)\n",
    "    mel = mel[:, :T, :]\n",
    "    pad_frames = tf.maximum(0, T - tf.shape(mel)[1])\n",
    "    mel = tf.pad(mel, paddings=[[0, 0], [0, pad_frames], [0, 0]])\n",
    "\n",
    "    # give Keras a static shape\n",
    "    mel.set_shape([N_MELS, T, 1])\n",
    "\n",
    "    return mel, tf.cast(label, tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42afa0f8",
   "metadata": {},
   "source": [
    "tf.data pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 32 # samples ber batch\n",
    "\n",
    "# Computing mel-spectrograms on-the-fly is extremely slow\n",
    "# To fix this, we preprocess each WAV file once and save the mel-spectrogram as a .npy file. Future runs load the .npy instantly\n",
    "# This caching optimization resulted in a 6x speedup for training time\n",
    "\n",
    "# one-time precompute pass (can be interrupted/resumed)\n",
    "import numpy as np, os, hashlib\n",
    "def mel_cache_path(wav_path):\n",
    "    h = hashlib.md5(wav_path.encode()).hexdigest()\n",
    "    return os.path.join(\"mel_store\", h + \".npy\")\n",
    "\n",
    "os.makedirs(\"mel_store\", exist_ok=True)\n",
    "\n",
    "# For each WAV file path:\n",
    "#      - compute its cache .npy file name\n",
    "#      - if the .npy file does NOT exist:\n",
    "#            load the WAV → compute mel → save to disk\n",
    "#      - return a list of .npy file paths\n",
    "def materialize(paths):\n",
    "    out = []\n",
    "    for p in paths:\n",
    "        npy = mel_cache_path(p)\n",
    "        if not os.path.exists(npy):\n",
    "            mel = load_mel(p)                  \n",
    "            np.save(npy, mel.astype(np.float32))\n",
    "        out.append(npy)\n",
    "    return out\n",
    "\n",
    "train_mels = materialize(train_paths)\n",
    "val_mels   = materialize(val_paths)\n",
    "eval_mels  = materialize(eval_paths)\n",
    "\n",
    "# takes path to cached mel file and one-hot multi-label vector and returns the mel tensor shape and a label as a float32 tensor\n",
    "def npy_loader(npy_path, label):\n",
    "    def _load(x):\n",
    "        if isinstance(x, (bytes, np.bytes_)):\n",
    "            x = x.decode()\n",
    "        return np.load(x)\n",
    "    # Loading the mel\n",
    "    mel = tf.numpy_function(_load, [npy_path], tf.float32)\n",
    "    mel.set_shape([N_MELS, None, 1])\n",
    "\n",
    "    # crop/pad along time axis to T frames\n",
    "    mel = mel[:, :T, :]                      # crop if too long\n",
    "    pad_frames = tf.maximum(0, T - tf.shape(mel)[1])\n",
    "    mel = tf.pad(mel, [[0, 0], [0, pad_frames], [0, 0]])\n",
    "\n",
    "    # static shape: (N_MELS, T, 1) so Keras is happy\n",
    "    mel.set_shape([N_MELS, T, 1])\n",
    "\n",
    "    return mel, tf.cast(label, tf.float32)\n",
    "\n",
    "def make_cached_ds(npy_paths, labels, shuffle):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((npy_paths, labels))\n",
    "    ds = ds.map(npy_loader, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle: ds = ds.shuffle(2048)\n",
    "    return ds.batch(BATCH).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_cached_ds(train_mels, y_train, True)\n",
    "val_ds   = make_cached_ds(val_mels,   y_val,   False)\n",
    "test_ds  = make_cached_ds(eval_mels,  y_eval,  False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0bb8c",
   "metadata": {},
   "source": [
    "CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fddae63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">647</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">647</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">647</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">647</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,400</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m647\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m647\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m647\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m647\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m51,400\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">441,160</span> (1.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m441,160\u001b[0m (1.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">440,200</span> (1.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m440,200\u001b[0m (1.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers as L, models\n",
    "\n",
    "\"\"\"\n",
    "Build a convolutional neural network (CNN) for multi-label audio classification.\n",
    "Input: log-mel spectrograms of shape [N_MELS, frames, 1]\n",
    "Output: per-class probabilities (sigmoid activation) for n_classes labels.\n",
    "\"\"\"\n",
    "def build_model(n_classes=NUM_CLASSES, input_shape=(N_MELS, None, 1)):\n",
    "    # input layer, takes a mel-spectrogram with a fixed # of mel bins, fixed # of time frames, and one channel\n",
    "    inp = L.Input(shape=(N_MELS, math.ceil((SR*DURATION)/HOP_LENGTH)+1, 1))\n",
    "\n",
    "    # First conv. block with 32 filters, 3x3 kernel size, batch normalization for stabalizing, and ReLU for nonlinearity\n",
    "    x = L.Conv2D(32, 3, padding=\"same\")(inp); x = L.BatchNormalization()(x); x = L.ReLU()(x)\n",
    "    x = L.MaxPool2D((2,2))(x)\n",
    "\n",
    "    # Second conv. block\n",
    "    x = L.Conv2D(64, 3, padding=\"same\")(x); x = L.BatchNormalization()(x); x = L.ReLU()(x)\n",
    "    x = L.MaxPool2D((2,2))(x)\n",
    "\n",
    "    # third conv. block\n",
    "    x = L.Conv2D(128, 3, padding=\"same\")(x); x = L.BatchNormalization()(x); x = L.ReLU()(x)\n",
    "    x = L.MaxPool2D((2,2))(x)\n",
    "\n",
    "    # fourth conv. block\n",
    "    x = L.Conv2D(256, 3, padding=\"same\")(x); x = L.BatchNormalization()(x); x = L.ReLU()(x)\n",
    "\n",
    "    # Global pooling to aggregate each feature map into a single val\n",
    "    # compact representation for a clip\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Done to reduce overfitting\n",
    "    x = L.Dropout(0.3)(x)\n",
    "\n",
    "    # Output layer, one neuron per class, independent probabilities per class for multi-label classification\n",
    "    out = L.Dense(n_classes, activation=\"sigmoid\")(x)  # multi-label → sigmoid\n",
    "\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4), # general learning rate\n",
    "    loss=keras.losses.BinaryCrossentropy(), # so each class ifs treated as a separate yes/no prediction\n",
    "\n",
    "    # AUPRC (Area under Precision-Recall curve) - good for imbalanced data.\n",
    "    # AUROC (Area under ROC curve) - general discriminative metric.\n",
    "    metrics=[\n",
    "        keras.metrics.AUC(curve=\"PR\", multi_label=True, num_labels=NUM_CLASSES, name=\"AUPRC\"),\n",
    "        keras.metrics.AUC(curve=\"ROC\", multi_label=True, num_labels=NUM_CLASSES, name=\"AUROC\")\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3b664",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d20b4df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - AUPRC: 0.0274 - AUROC: 0.4849 - loss: 0.1413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 320ms/step - AUPRC: 0.0362 - AUROC: 0.6254 - loss: 0.0740 - val_AUPRC: 0.0281 - val_AUROC: 0.5344 - val_loss: 0.0858 - learning_rate: 3.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - AUPRC: 0.0578 - AUROC: 0.5736 - loss: 0.0472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 299ms/step - AUPRC: 0.0838 - AUROC: 0.7465 - loss: 0.0456 - val_AUPRC: 0.0387 - val_AUROC: 0.5845 - val_loss: 0.0811 - learning_rate: 3.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - AUPRC: 0.0762 - AUROC: 0.6078 - loss: 0.0438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 306ms/step - AUPRC: 0.1125 - AUROC: 0.7881 - loss: 0.0423 - val_AUPRC: 0.0484 - val_AUROC: 0.6160 - val_loss: 0.0763 - learning_rate: 3.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - AUPRC: 0.0941 - AUROC: 0.6391 - loss: 0.0410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 294ms/step - AUPRC: 0.1402 - AUROC: 0.8245 - loss: 0.0396 - val_AUPRC: 0.0589 - val_AUROC: 0.6510 - val_loss: 0.0758 - learning_rate: 3.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - AUPRC: 0.1131 - AUROC: 0.6727 - loss: 0.0388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 294ms/step - AUPRC: 0.1696 - AUROC: 0.8522 - loss: 0.0375 - val_AUPRC: 0.0642 - val_AUROC: 0.6463 - val_loss: 0.0795 - learning_rate: 3.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - AUPRC: 0.1307 - AUROC: 0.6907 - loss: 0.0367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 292ms/step - AUPRC: 0.1970 - AUROC: 0.8744 - loss: 0.0357 - val_AUPRC: 0.0765 - val_AUROC: 0.6749 - val_loss: 0.0738 - learning_rate: 3.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - AUPRC: 0.1464 - AUROC: 0.7081 - loss: 0.0350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 293ms/step - AUPRC: 0.2232 - AUROC: 0.8925 - loss: 0.0341 - val_AUPRC: 0.0873 - val_AUROC: 0.6946 - val_loss: 0.0715 - learning_rate: 3.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - AUPRC: 0.1619 - AUROC: 0.7226 - loss: 0.0335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 293ms/step - AUPRC: 0.2488 - AUROC: 0.9058 - loss: 0.0327 - val_AUPRC: 0.0960 - val_AUROC: 0.6967 - val_loss: 0.0703 - learning_rate: 3.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - AUPRC: 0.1773 - AUROC: 0.7382 - loss: 0.0322"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 293ms/step - AUPRC: 0.2724 - AUROC: 0.9167 - loss: 0.0316 - val_AUPRC: 0.1002 - val_AUROC: 0.7084 - val_loss: 0.0700 - learning_rate: 3.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - AUPRC: 0.1882 - AUROC: 0.7372 - loss: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 292ms/step - AUPRC: 0.2906 - AUROC: 0.9221 - loss: 0.0306 - val_AUPRC: 0.1110 - val_AUROC: 0.7130 - val_loss: 0.0684 - learning_rate: 3.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 293ms/step - AUPRC: 0.3111 - AUROC: 0.9283 - loss: 0.0297 - val_AUPRC: 0.1039 - val_AUROC: 0.6867 - val_loss: 0.0726 - learning_rate: 3.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - AUPRC: 0.2119 - AUROC: 0.7532 - loss: 0.0293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 293ms/step - AUPRC: 0.3312 - AUROC: 0.9331 - loss: 0.0289 - val_AUPRC: 0.1205 - val_AUROC: 0.7234 - val_loss: 0.0688 - learning_rate: 3.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - AUPRC: 0.2188 - AUROC: 0.7568 - loss: 0.0286\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 293ms/step - AUPRC: 0.3440 - AUROC: 0.9369 - loss: 0.0283 - val_AUPRC: 0.1118 - val_AUROC: 0.6913 - val_loss: 0.0718 - learning_rate: 3.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - AUPRC: 0.2292 - AUROC: 0.7650 - loss: 0.0286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 292ms/step - AUPRC: 0.3583 - AUROC: 0.9423 - loss: 0.0279 - val_AUPRC: 0.1354 - val_AUROC: 0.7237 - val_loss: 0.0703 - learning_rate: 1.5000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 293ms/step - AUPRC: 0.3723 - AUROC: 0.9439 - loss: 0.0273 - val_AUPRC: 0.1351 - val_AUROC: 0.7270 - val_loss: 0.0678 - learning_rate: 1.5000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - AUPRC: 0.2420 - AUROC: 0.7649 - loss: 0.0271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 294ms/step - AUPRC: 0.3815 - AUROC: 0.9468 - loss: 0.0268 - val_AUPRC: 0.1536 - val_AUROC: 0.7613 - val_loss: 0.0639 - learning_rate: 1.5000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 293ms/step - AUPRC: 0.3909 - AUROC: 0.9482 - loss: 0.0264 - val_AUPRC: 0.1420 - val_AUROC: 0.7349 - val_loss: 0.0664 - learning_rate: 1.5000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 292ms/step - AUPRC: 0.4008 - AUROC: 0.9489 - loss: 0.0261 - val_AUPRC: 0.1424 - val_AUROC: 0.7334 - val_loss: 0.0670 - learning_rate: 1.5000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - AUPRC: 0.2580 - AUROC: 0.7674 - loss: 0.0259\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 294ms/step - AUPRC: 0.4104 - AUROC: 0.9499 - loss: 0.0257 - val_AUPRC: 0.1479 - val_AUROC: 0.7368 - val_loss: 0.0662 - learning_rate: 1.5000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 292ms/step - AUPRC: 0.4131 - AUROC: 0.9521 - loss: 0.0256 - val_AUPRC: 0.1470 - val_AUROC: 0.7310 - val_loss: 0.0667 - learning_rate: 7.5000e-05\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.5, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\"fsd50k_cnn.h5\", monitor=\"val_AUPRC\", mode=\"max\", save_best_only=True),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf0343e",
   "metadata": {},
   "source": [
    "Getting Evaluation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f436acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 98ms/step - AUPRC: 0.1429 - AUROC: 0.7442 - loss: 0.0836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUPRC': 0.14291605353355408,\n",
       " 'AUROC': 0.7442101836204529,\n",
       " 'loss': 0.083570696413517}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.load_weights(\"fsd50k_cnn.h5\")\n",
    "metrics = model.evaluate(test_ds, return_dict=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6f2218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 86ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics with a threshold of 0.5\n",
      "Micro Accuracy: 0.9816342488515296\n",
      "Micro Precision: 0.5587419056429233\n",
      "Micro Recall: 0.12519432065499014\n",
      "Micro F1: 0.20455507577681822 \n",
      "\n",
      "Macro Accuracy: 0.9816342488419348\n",
      "Macro Precision: 0.13007667595782718\n",
      "Macro Recall: 0.03074771039874952\n",
      "Macro F1: 0.03845799807178719 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics with a threshold of 0.25\n",
      "Micro Accuracy: 0.9786707066757893\n",
      "Micro Precision: 0.38542896050839764\n",
      "Micro Recall: 0.21999689086952015\n",
      "Micro F1: 0.28011084353247784 \n",
      "\n",
      "Macro Accuracy: 0.9786707066662234\n",
      "Macro Precision: 0.15921206312055644\n",
      "Macro Recall: 0.07806428375830234\n",
      "Macro F1: 0.06997934826855841 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics with a threshold of 0.1\n",
      "Micro Accuracy: 0.9678340338187861\n",
      "Micro Precision: 0.24253773691975938\n",
      "Micro Recall: 0.332210591771168\n",
      "Micro F1: 0.28037873652445827 \n",
      "\n",
      "Macro Accuracy: 0.9678340338093261\n",
      "Macro Precision: 0.15882723699682674\n",
      "Macro Recall: 0.15709384629255976\n",
      "Macro F1: 0.09823427578646429 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics with a threshold of 0.05\n",
      "Micro Accuracy: 0.9520457433290979\n",
      "Micro Precision: 0.1753136249590924\n",
      "Micro Recall: 0.4163902995129029\n",
      "Micro F1: 0.2467412832204873 \n",
      "\n",
      "Macro Accuracy: 0.9520457433197923\n",
      "Macro Precision: 0.16748673971419056\n",
      "Macro Recall: 0.23453130960033491\n",
      "Macro F1: 0.11731576364294045 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics with a threshold of 0.02\n",
      "Micro Accuracy: 0.9158953181507185\n",
      "Micro Precision: 0.11761942679720215\n",
      "Micro Recall: 0.5319722251010467\n",
      "Micro F1: 0.1926449270263043 \n",
      "\n",
      "Macro Accuracy: 0.9158953181417661\n",
      "Macro Precision: 0.14476551297037396\n",
      "Macro Recall: 0.35792810050747653\n",
      "Macro F1: 0.13354099712541323 \n",
      "\n",
      "Evaluation Metrics with a threshold of 0.01\n",
      "Micro Accuracy: 0.8720731111328316\n",
      "Micro Precision: 0.08861828182951018\n",
      "Micro Recall: 0.6227847445331123\n",
      "Micro F1: 0.15515850218501281 \n",
      "\n",
      "Macro Accuracy: 0.8720731111243076\n",
      "Macro Precision: 0.12314062243320681\n",
      "Macro Recall: 0.46771676862125766\n",
      "Macro F1: 0.1322362609744049 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Predict probabilities for every evaluation example\n",
    "y_prob = model.predict(test_ds, verbose=1)\n",
    "\n",
    "# Convert to 0/1 predictions using a threshold\n",
    "thresholds = [0.5, 0.25, 0.1, 0.05, 0.02, 0.01]\n",
    "for t in thresholds:\n",
    "    y_pred = (y_prob > t).astype(int)\n",
    "    \n",
    "    precision_micro = precision_score(y_eval, y_pred, average='micro')\n",
    "    recall_micro    = recall_score(y_eval, y_pred, average='micro')\n",
    "    f1_micro        = f1_score(y_eval, y_pred, average='micro')\n",
    "    accuracy_micro  = accuracy_micro = accuracy_score(y_eval.flatten(), y_pred.flatten())\n",
    "\n",
    "    precision_macro = precision_score(y_eval, y_pred, average='macro')\n",
    "    recall_macro    = recall_score(y_eval, y_pred, average='macro')\n",
    "    f1_macro        = f1_score(y_eval, y_pred, average='macro')\n",
    "    accuracies = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        tp = np.sum((y_eval[:, i] == 1) & (y_pred[:, i] == 1))\n",
    "        tn = np.sum((y_eval[:, i] == 0) & (y_pred[:, i] == 0))\n",
    "        fp = np.sum((y_eval[:, i] == 0) & (y_pred[:, i] == 1))\n",
    "        fn = np.sum((y_eval[:, i] == 1) & (y_pred[:, i] == 0))\n",
    "\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn + 1e-7)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    accuracy_macro = np.mean(accuracies)\n",
    "\n",
    "    print(\"Evaluation Metrics with a threshold of\", t)\n",
    "    print(\"Micro Accuracy:\", accuracy_micro)\n",
    "    print(\"Micro Precision:\", precision_micro)\n",
    "    print(\"Micro Recall:\", recall_micro)\n",
    "    print(\"Micro F1:\", f1_micro, '\\n')\n",
    "\n",
    "    print(\"Macro Accuracy:\", accuracy_macro)\n",
    "    print(\"Macro Precision:\", precision_macro)\n",
    "    print(\"Macro Recall:\", recall_macro)\n",
    "    print(\"Macro F1:\", f1_macro, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30543f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "            Accelerating_and_revving_and_vroom       0.09      0.61      0.15       114\n",
      "                                     Accordion       0.00      0.00      0.00        50\n",
      "                               Acoustic_guitar       0.33      0.04      0.08       134\n",
      "                                      Aircraft       0.06      0.81      0.12        88\n",
      "                                         Alarm       0.35      0.46      0.40       584\n",
      "                                        Animal       0.17      0.89      0.29      1082\n",
      "                                      Applause       0.00      0.00      0.00       150\n",
      "                                          Bark       0.00      0.00      0.00       122\n",
      "                                     Bass_drum       0.00      0.00      0.00       119\n",
      "                                   Bass_guitar       0.25      0.01      0.02        78\n",
      "                  Bathtub_(filling_or_washing)       0.07      0.44      0.13        55\n",
      "                                          Bell       0.39      0.35      0.37       386\n",
      "                                       Bicycle       0.11      0.31      0.16       100\n",
      "                                  Bicycle_bell       0.19      0.16      0.17        56\n",
      "                                          Bird       0.56      0.26      0.36       540\n",
      " Bird_vocalization_and_bird_call_and_bird_song       0.65      0.16      0.26       459\n",
      "                        Boat_and_Water_vehicle       0.02      0.30      0.04        33\n",
      "                                       Boiling       0.00      0.00      0.00        37\n",
      "                                          Boom       0.05      0.70      0.10        37\n",
      "                       Bowed_string_instrument       0.15      0.69      0.24       140\n",
      "                              Brass_instrument       0.14      0.06      0.08        86\n",
      "                                     Breathing       0.67      0.04      0.07       227\n",
      "                        Burping_and_eructation       0.00      0.00      0.00        92\n",
      "                                           Bus       0.03      0.84      0.07        62\n",
      "                                          Buzz       0.00      0.00      0.00        76\n",
      "                                        Camera       0.08      0.55      0.14        76\n",
      "                                           Car       0.14      0.08      0.10       326\n",
      "                                Car_passing_by       0.18      0.06      0.09       106\n",
      "                                           Cat       0.33      0.01      0.01       132\n",
      "                                       Chatter       0.00      0.00      0.00       387\n",
      "                                      Cheering       0.00      0.00      0.00       109\n",
      "                       Chewing_and_mastication       0.00      0.00      0.00        75\n",
      "                           Chicken_and_rooster       0.02      0.26      0.04        35\n",
      "                 Child_speech_and_kid_speaking       0.05      0.44      0.09        97\n",
      "                                         Chime       0.54      0.14      0.22       102\n",
      "                               Chink_and_clink       0.10      0.61      0.17       168\n",
      "                               Chirp_and_tweet       0.69      0.12      0.20       354\n",
      "                           Chuckle_and_chortle       0.00      0.00      0.00        52\n",
      "                                   Church_bell       0.14      0.33      0.20        60\n",
      "                                      Clapping       0.00      0.00      0.00       188\n",
      "                                         Clock       0.27      0.16      0.21        97\n",
      "                               Coin_(dropping)       0.22      0.02      0.04        92\n",
      "                             Computer_keyboard       0.17      0.49      0.25        93\n",
      "                                  Conversation       0.08      0.62      0.14        61\n",
      "                                         Cough       0.21      0.21      0.21       106\n",
      "                                       Cowbell       0.00      0.00      0.00        63\n",
      "                                         Crack       0.00      0.00      0.00        69\n",
      "                                       Crackle       0.06      0.66      0.11       107\n",
      "                                  Crash_cymbal       0.50      0.04      0.08        71\n",
      "                                       Cricket       0.24      0.45      0.31       100\n",
      "                                          Crow       0.16      0.33      0.21        36\n",
      "                                         Crowd       0.00      0.00      0.00       153\n",
      "                       Crumpling_and_crinkling       0.00      0.00      0.00        90\n",
      "                                      Crushing       0.04      0.76      0.08        86\n",
      "                            Crying_and_sobbing       0.00      0.00      0.00        42\n",
      "                        Cupboard_open_or_close       0.00      0.00      0.00        55\n",
      "                        Cutlery_and_silverware       0.00      0.00      0.00       126\n",
      "                                        Cymbal       0.78      0.06      0.11       234\n",
      "                      Dishes_and_pots_and_pans       0.11      0.01      0.01       149\n",
      "                                           Dog       0.30      0.04      0.07       178\n",
      "                     Domestic_animals_and_pets       0.35      0.09      0.14       311\n",
      "               Domestic_sounds_and_home_sounds       0.24      0.97      0.38      1947\n",
      "                                          Door       0.28      0.32      0.30       466\n",
      "                                      Doorbell       0.09      0.27      0.14        37\n",
      "                          Drawer_open_or_close       0.07      0.54      0.13        69\n",
      "                                         Drill       0.00      0.00      0.00        42\n",
      "                                          Drip       0.17      0.01      0.02        99\n",
      "                                          Drum       0.62      0.02      0.03       310\n",
      "                                      Drum_kit       0.29      0.03      0.06        60\n",
      "                               Electric_guitar       0.35      0.17      0.22       181\n",
      "                                        Engine       0.29      0.58      0.39       554\n",
      "                               Engine_starting       0.12      0.08      0.10        76\n",
      "                                     Explosion       0.34      0.47      0.39       266\n",
      "                                          Fart       0.00      0.00      0.00        97\n",
      "                                Female_singing       0.08      0.13      0.10        70\n",
      "              Female_speech_and_woman_speaking       0.33      0.09      0.15       247\n",
      "                            Fill_(with_liquid)       0.44      0.12      0.19        58\n",
      "                               Finger_snapping       0.07      0.18      0.10        67\n",
      "                                          Fire       0.00      0.00      0.00       124\n",
      "                                     Fireworks       0.00      0.00      0.00        67\n",
      "              Fixed-wing_aircraft_and_airplane       0.06      0.73      0.10        45\n",
      "                                          Fowl       0.02      0.75      0.05        57\n",
      "                                          Frog       0.09      0.42      0.15        38\n",
      "                                 Frying_(food)       0.00      0.00      0.00        57\n",
      "                                          Gasp       0.00      0.00      0.00        52\n",
      "                                        Giggle       0.54      0.08      0.14        84\n",
      "                                         Glass       0.12      0.59      0.19       267\n",
      "                                  Glockenspiel       0.79      0.44      0.56        87\n",
      "                                          Gong       0.25      0.22      0.24        72\n",
      "                                      Growling       0.00      0.00      0.00        51\n",
      "                                        Guitar       0.67      0.36      0.47       411\n",
      "                              Gull_and_seagull       0.00      0.00      0.00        32\n",
      "                           Gunshot_and_gunfire       1.00      0.01      0.01       134\n",
      "                                      Gurgling       0.04      0.38      0.07       101\n",
      "                                        Hammer       0.39      0.16      0.23        69\n",
      "                                         Hands       0.18      0.15      0.17       297\n",
      "                                     Harmonica       0.00      0.00      0.00        58\n",
      "                                          Harp       0.12      0.33      0.18        57\n",
      "                                        Hi-hat       0.00      0.00      0.00       146\n",
      "                                          Hiss       0.07      0.16      0.10       125\n",
      "                           Human_group_actions       0.25      0.00      0.00       631\n",
      "                                   Human_voice       0.50      0.58      0.54      1633\n",
      "                                        Idling       0.29      0.02      0.04       106\n",
      "                                        Insect       0.32      0.29      0.30       215\n",
      "                            Keyboard_(musical)       0.15      0.52      0.23       376\n",
      "                                 Keys_jangling       0.17      0.01      0.02        82\n",
      "                                         Knock       0.17      0.01      0.02       103\n",
      "                                      Laughter       0.36      0.07      0.11       253\n",
      "                                        Liquid       0.12      0.80      0.22       476\n",
      "Livestock_and_farm_animals_and_working_animals       0.02      0.96      0.04       120\n",
      "                                  Male_singing       0.26      0.20      0.23        70\n",
      "                  Male_speech_and_man_speaking       0.25      0.00      0.00       467\n",
      "                             Mallet_percussion       0.65      0.32      0.43       140\n",
      "                         Marimba_and_xylophone       0.00      0.00      0.00        39\n",
      "                                Mechanical_fan       0.00      0.00      0.00        55\n",
      "                                    Mechanisms       0.19      0.26      0.22       461\n",
      "                                          Meow       1.00      0.01      0.03        78\n",
      "                                Microwave_oven       0.04      0.20      0.06        66\n",
      "                          Motor_vehicle_(road)       0.18      0.74      0.29       587\n",
      "                                    Motorcycle       0.04      0.68      0.08        80\n",
      "                                         Music       0.43      0.91      0.58      1972\n",
      "                            Musical_instrument       0.43      0.92      0.58      1940\n",
      "                                         Ocean       0.05      0.88      0.10        93\n",
      "                                         Organ       0.02      0.69      0.03        35\n",
      "                    Packing_tape_and_duct_tape       0.00      0.00      0.00        60\n",
      "                                    Percussion       0.68      0.52      0.59       825\n",
      "                                         Piano       0.00      0.00      0.00        76\n",
      "                     Plucked_string_instrument       0.66      0.36      0.47       434\n",
      "                                          Pour       0.40      0.02      0.04       169\n",
      "                                    Power_tool       0.00      0.00      0.00        43\n",
      "                                       Printer       0.00      0.00      0.00        63\n",
      "                                          Purr       0.00      0.00      0.00        60\n",
      "                      Race_car_and_auto_racing       0.08      0.16      0.11        51\n",
      "                                Rail_transport       0.00      0.00      0.00       199\n",
      "                                          Rain       0.00      0.00      0.00       208\n",
      "                                      Raindrop       0.00      0.00      0.00        75\n",
      "                              Ratchet_and_pawl       0.00      0.00      0.00        54\n",
      "                                        Rattle       0.00      0.00      0.00       127\n",
      "                           Rattle_(instrument)       0.55      0.34      0.42        64\n",
      "                            Respiratory_sounds       0.34      0.38      0.36       380\n",
      "                                      Ringtone       0.00      0.00      0.00        72\n",
      "                                           Run       0.19      0.37      0.25        91\n",
      "                                        Sawing       0.11      0.73      0.20        55\n",
      "                                      Scissors       0.17      0.10      0.13        59\n",
      "            Scratching_(performance_technique)       0.07      0.80      0.13        81\n",
      "                                     Screaming       0.00      0.00      0.00       123\n",
      "                                       Screech       0.00      0.00      0.00        68\n",
      "                                       Shatter       0.14      0.03      0.05        96\n",
      "                                         Shout       0.12      0.05      0.07       177\n",
      "                                          Sigh       0.00      0.00      0.00        61\n",
      "                                       Singing       0.28      0.27      0.27       194\n",
      "                     Sink_(filling_or_washing)       0.08      0.87      0.14       115\n",
      "                                         Siren       0.00      0.00      0.00        55\n",
      "                                    Skateboard       0.00      0.00      0.00        52\n",
      "                                          Slam       0.22      0.29      0.25       201\n",
      "                                  Sliding_door       0.00      0.00      0.00        99\n",
      "                                    Snare_drum       0.00      0.00      0.00       145\n",
      "                                        Sneeze       0.00      0.00      0.00        61\n",
      "                                        Speech       0.24      0.48      0.32       785\n",
      "                            Speech_synthesizer       0.00      0.00      0.00        61\n",
      "                           Splash_and_splatter       0.11      0.01      0.01       144\n",
      "                                        Squeak       0.00      0.00      0.00       217\n",
      "                                        Stream       0.00      0.00      0.00       103\n",
      "                                         Strum       0.18      0.16      0.17        57\n",
      "              Subway_and_metro_and_underground       0.00      0.00      0.00        82\n",
      "                                         Tabla       0.00      0.00      0.00        45\n",
      "                                    Tambourine       0.07      0.24      0.11        71\n",
      "                                           Tap       0.00      0.00      0.00       136\n",
      "                                       Tearing       0.04      0.88      0.08       110\n",
      "                                     Telephone       0.15      0.64      0.24       165\n",
      "                                Thump_and_thud       0.23      0.03      0.05       171\n",
      "                                       Thunder       0.33      0.01      0.02       128\n",
      "                                  Thunderstorm       0.46      0.14      0.21       132\n",
      "                                          Tick       0.00      0.00      0.00        57\n",
      "                                     Tick-tock       0.22      0.09      0.13        74\n",
      "                                  Toilet_flush       0.06      0.89      0.11        73\n",
      "                                         Tools       0.05      0.74      0.09       216\n",
      "               Traffic_noise_and_roadway_noise       0.09      0.46      0.15       127\n",
      "                                         Train       0.00      0.00      0.00       111\n",
      "                           Trickle_and_dribble       0.60      0.06      0.11       154\n",
      "                                         Truck       0.00      0.00      0.00        44\n",
      "                                       Trumpet       0.43      0.05      0.10        56\n",
      "                                    Typewriter       0.04      0.04      0.04        51\n",
      "                                        Typing       0.11      0.70      0.19       146\n",
      "                                       Vehicle       0.25      0.79      0.38      1030\n",
      "         Vehicle_horn_and_car_horn_and_honking       0.00      0.00      0.00        68\n",
      "                            Walk_and_footsteps       0.00      0.00      0.00       203\n",
      "                                         Water       0.16      0.89      0.27       565\n",
      "                          Water_tap_and_faucet       0.16      0.85      0.27       178\n",
      "                                Waves_and_surf       0.05      0.90      0.09        78\n",
      "                                    Whispering       0.00      0.00      0.00        75\n",
      "                   Whoosh_and_swoosh_and_swish       0.19      0.37      0.26       100\n",
      "                                  Wild_animals       0.44      0.46      0.45       751\n",
      "                                          Wind       0.00      0.00      0.00       134\n",
      "                                    Wind_chime       0.22      0.04      0.06        53\n",
      "       Wind_instrument_and_woodwind_instrument       0.20      0.09      0.12       105\n",
      "                                          Wood       0.00      0.00      0.00       147\n",
      "                                       Writing       0.00      0.00      0.00        88\n",
      "                                          Yell       0.08      0.08      0.08        60\n",
      "                             Zipper_(clothing)       0.18      0.02      0.03       104\n",
      "\n",
      "                                     micro avg       0.18      0.42      0.25     38596\n",
      "                                     macro avg       0.17      0.23      0.12     38596\n",
      "                                  weighted avg       0.27      0.42      0.25     38596\n",
      "                                   samples avg       0.19      0.43      0.25     38596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Austin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Austin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = (y_prob > 0.05).astype(int)\n",
    "print(classification_report(y_eval, y_pred, target_names=all_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1ef25",
   "metadata": {},
   "source": [
    "Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a19337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_true = y_eval\n",
    "conf_matrices = []\n",
    "\n",
    "# Obtains a confusion matrix for each of the 200 classes\n",
    "for i in range(NUM_CLASSES):\n",
    "    cm = confusion_matrix(y_true[:, i], y_pred[:, i], labels=[0,1])\n",
    "    conf_matrices.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6833eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle_horn_and_car_horn_and_honking\n",
      "[[10160     3]\n",
      " [   68     0]]\n"
     ]
    }
   ],
   "source": [
    "# Code to display the confusion matrix for a selected class\n",
    "k = 185  # pick any class index\n",
    "print(all_labels[k])\n",
    "print(conf_matrices[k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65efb6ad",
   "metadata": {},
   "source": [
    "Predictions on any specific evaluation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f633819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top k class predictions with scores for a given audio file path\n",
    "def predict_clip(path, k=5):\n",
    "    x, _ = tf_load_mel(tf.convert_to_tensor(path), tf.zeros([NUM_CLASSES], tf.float32))\n",
    "    x = tf.expand_dims(x, 0)\n",
    "    probs = model.predict(x, verbose=0)[0]\n",
    "    topk = probs.argsort()[-k:][::-1]\n",
    "\n",
    "    print(path)\n",
    "\n",
    "    return [(all_labels[i], float(probs[i])) for i in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9146a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSD50K/FSD50K.eval_audio/117304.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Liquid', 0.8960501551628113),\n",
       " ('Domestic_sounds_and_home_sounds', 0.3265989124774933),\n",
       " ('Animal', 0.06631539762020111),\n",
       " ('Water', 0.019509442150592804),\n",
       " ('Sink_(filling_or_washing)', 0.013542539440095425)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example to get predictions for an audio file\n",
    "predict_clip(\"FSD50K/FSD50K.eval_audio/117304.wav\", k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
